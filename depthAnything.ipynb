{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c048f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2 cuda devices 1\n",
      "Torch using cuda\n",
      "/home/nick/OSMLoc\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "\n",
    "print(f\"cv2 cuda devices {cv2.cuda.getCudaEnabledDeviceCount()}\")\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "print(f\"Torch using {DEVICE}\")\n",
    "\n",
    "os.chdir('/home/nick/OSMLoc')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "409bd053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vitl\n",
      "Model created. Checking weight loading...\n",
      "Error checking weights: 'ReLU' object has no attribute 'weight'\n",
      "Weight depth_head.projects.0.weight - mean: 0.000082, std: 0.018046\n",
      "Loaded Model on cuda\n",
      "Total parameters: 336,875,201, Non-zero parameters: 336,601,524\n",
      "Percentage of non-zero weights: 99.92%\n",
      "Input tensor shape: torch.Size([1, 3, 518, 686]), device: cuda:0\n",
      "Input tensor stats - min: -2.5030, max: 3.0917, mean: 0.0715\n",
      "Starting forward pass...\n",
      "Got Depth map with shape: (518, 686)\n",
      "Depth stats - min: 0.0000, max: 0.0000, mean: 0.0000\n",
      "Before normalization - min: 0.0000, max: 0.0000\n",
      "After normalization - min: 0, max: 0\n",
      "Saved depth map to depth.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from maploc.models.depth_anything.dpt import DepthAnything\n",
    "\n",
    "# Configuration for DepthAnything model - based on osmloc configuration\n",
    "config = {\n",
    "    'encoder': 'vitl',           # encoder type: 'vits', 'vitb', or 'vitl'\n",
    "    'features': 256,            # feature dimension\n",
    "    'out_dim': 128,             # output dimension\n",
    "    'out_channels': [256, 512, 1024, 1024],  # output channels for each layer\n",
    "    # 'ckpt': 'maploc/models/depth_anything/ckpt/depth_anything_vitl14.pth',  # checkpoint path\n",
    "    'use_bn': False,            # use batch normalization\n",
    "    'use_clstoken': False,      # use class token\n",
    "    'localhub': True,           # load DINOv2 from local hub\n",
    "    'size': [518, 518],        # input size\n",
    "    'val': False               # validation mode\n",
    "}\n",
    "\n",
    "# Create the model with the proper configuration\n",
    "# The DepthAnything class expects the config dict and will unpack it\n",
    "\n",
    "# model = DepthAnything.from_pretrained(\"LiheYoung/depth_anything_{:}14\".format(config.encoder))\n",
    "# Create the model with debugging to check weight loading\n",
    "model = DepthAnything(config)\n",
    "\n",
    "# Check if weights were loaded properly\n",
    "print(f\"Model created. Checking weight loading...\")\n",
    "try:\n",
    "    depth_conv_weight = model.depth_head.scratch.output_conv2[1].weight\n",
    "    print(f\"Depth head output conv weight mean: {depth_conv_weight.mean().item():.6f}\")\n",
    "    print(f\"Depth head output conv weight std: {depth_conv_weight.std().item():.6f}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error checking weights: {e}\")\n",
    "    # Try alternative weight checking\n",
    "    try:\n",
    "        for name, param in model.named_parameters():\n",
    "            if 'depth' in name.lower() and param.dim() > 1:\n",
    "                print(f\"Weight {name} - mean: {param.mean().item():.6f}, std: {param.std().item():.6f}\")\n",
    "                break\n",
    "    except Exception as e2:\n",
    "        print(f\"Alternative weight check also failed: {e2}\")\n",
    "\n",
    "model = model.to(DEVICE).eval()\n",
    "\n",
    "print(f\"Loaded Model on {DEVICE}\")\n",
    "\n",
    "# Additional check: verify checkpoint was loaded by checking if weights are non-zero\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "non_zero_params = sum((p != 0).sum().item() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params:,}, Non-zero parameters: {non_zero_params:,}\")\n",
    "print(f\"Percentage of non-zero weights: {100 * non_zero_params / total_params:.2f}%\" if total_params > 0 else \"No parameters found\")\n",
    "\n",
    "\n",
    "# Convert image to tensor and normalize\n",
    "from torchvision.transforms import Compose\n",
    "from maploc.models.depth_anything.util.transform import Resize, NormalizeImage, PrepareForNet\n",
    "\n",
    "transform = Compose([\n",
    "    Resize(\n",
    "        width=518,\n",
    "        height=518,\n",
    "        resize_target=False,\n",
    "        keep_aspect_ratio=True,\n",
    "        ensure_multiple_of=14,\n",
    "        resize_method='lower_bound',\n",
    "        image_interpolation_method=cv2.INTER_CUBIC,\n",
    "    ),\n",
    "    NormalizeImage(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    PrepareForNet(),\n",
    "])\n",
    "\n",
    "image = cv2.cvtColor(cv2.imread('IMG_20250327_105752435_HDR.jpg'), cv2.COLOR_BGR2RGB) / 255.0\n",
    "image = transform({'image': image})['image']\n",
    "# Debug input tensor\n",
    "image = torch.from_numpy(image).unsqueeze(0).to(DEVICE)\n",
    "print(f\"Input tensor shape: {image.shape}, device: {image.device}\")\n",
    "print(f\"Input tensor stats - min: {image.min().item():.4f}, max: {image.max().item():.4f}, mean: {image.mean().item():.4f}\")\n",
    "\n",
    "# Forward pass with detailed debugging\n",
    "print(\"Starting forward pass...\")\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "    \n",
    "\n",
    "\n",
    "# Remove batch dimension and squeeze to get 2D array\n",
    "depth = output[\"simple\"].cpu().detach().numpy().squeeze()  # This removes the batch dimension\n",
    "\n",
    "print(f\"Got Depth map with shape: {depth.shape}\")\n",
    "print(f\"Depth stats - min: {depth.min():.4f}, max: {depth.max():.4f}, mean: {depth.mean():.4f}\")\n",
    "\n",
    "# Debug: check depth values before normalization\n",
    "print(f\"Before normalization - min: {depth.min():.4f}, max: {depth.max():.4f}\")\n",
    "depth_normalized = cv2.normalize(depth, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "print(f\"After normalization - min: {depth_normalized.min()}, max: {depth_normalized.max()}\")\n",
    "\n",
    "# Save depth map\n",
    "cv2.imwrite('depth.png', depth_normalized)\n",
    "print(f\"Saved depth map to depth.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
